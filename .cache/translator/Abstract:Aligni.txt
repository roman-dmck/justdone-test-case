Анотація: Узгодження мовних моделей із намірами користувача стає все більш актуальним для покращення досвіду користувачів. Це вимагає розробки методів, які дозволяють користувачам контролювати властивості генерованої мовою, наприклад, довжину генерації, складність обраної мови, емоційний тон, стиль тощо. Більшість існуючих підходів намагаються інтегрувати контроль користувача шляхом умовної генерації мовних моделей на основі природних мовних підказок або дискретних сигнальних контролів, що часто є крихкими та важкими для масштабування. У цій роботі ми зосереджуємося на непреривчастих сигналах контролю, які існують у спектрі, що важко точно зафіксувати у природній мовній підказці або за допомогою існуючих технік умовної генерації. Провівши кейс-стаді з контролю точної довжини відповідей, які генерують мовні моделі, ми демонструємо, що після донавчання поведінка мовних моделей може контролюватися за допомогою непреривчастих сигналів — у вигляді векторів, які інтерполюють між "низьким" і "високим" вбудовуванням токенів. Наш метод більш надійно забезпечує контроль довжини відповіді порівняно з методами навчання у контексті або методами донавчання, що представляють сигнал контролю у вигляді дискретного сигналу. Наш повний відкритий код та набори даних доступні за цим https URL.