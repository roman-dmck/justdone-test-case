Анотація: Автогресивні (AR) моделі останнім часом демонструють високі результати у генерації зображень, де ключовим компонентом є візуальний токенізатор (VT), який перетворює безперервний потік пікселів у дискретні послідовності токенів. Якість VT значною мірою визначає верхню межу продуктивності AR-моделей. Однак сучасні дискретні VT значно поступаються континуальним варіаційним автокодерам (VAE), що призводить до погіршення відтворення зображень та поганого збереження деталей і тексту. Існуючі бенчмарки зосереджені на якості кінцевої генерації без окремої оцінки продуктивності VT. Щоб заповнити цю прогалину, ми представляємо VTBench — всеохоплюючий бенчмарк, який систематично оцінює VT за трьома основними завданнями: відновлення зображень, збереження деталей та збереження тексту, охоплюючи широкий спектр сценаріїв оцінювання. Ми систематично аналізуємо сучасні VT за допомогою набору метрик для оцінки якості відновлених зображень. Наші дослідження показують, що континуальні VAE створюють кращі візуальні репрезентації порівняно з дискретними VT, особливо у збереженні просторової структури та семантичних деталей. Навпаки, погані репрезентації, створені дискретними VT, часто призводять до спотворених відтворень, втрати дрібних текстур і невдач у збереженні тексту та цілісності об’єктів. Крім того, ми провели експерименти з генерацією зображень за допомогою GPT-4o та обговорили його потенційну AR-природу, що відкриває нові перспективи у розумінні ролі візуальної токенізації. Ми публічно випускаємо наш бенчмарк і кодову базу для підтримки подальших досліджень і закликаємо спільноту до розробки потужних, універсальних відкритих VT.